{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read file (.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "''' Read input files '''\n",
    "my_data = np.genfromtxt('pkgo_city66_class5_v1.csv', delimiter=',',skip_header=1)\n",
    "my_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' The first column to the 199th column is used as input features '''\n",
    "X_train = my_data[:,0:200]\n",
    "X_train = X_train.astype('float32')\n",
    "\n",
    "''' The 200-th column is the answer '''\n",
    "y_train = my_data[:,200]\n",
    "y_train = y_train.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The target looks like that ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Convert to one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "Y_train = np_utils.to_categorical(y_train,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Shuffle training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X_train,Y_train = shuffle(X_train,Y_train,random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import keras to build a DL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function\n",
    "## Building a model with categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ce = Sequential()\n",
    "model_ce.add(Dense(128, input_dim=200))\n",
    "model_ce.add(Activation('sigmoid'))\n",
    "model_ce.add(Dense(256))\n",
    "model_ce.add(Activation('sigmoid'))\n",
    "model_ce.add(Dense(5))\n",
    "model_ce.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a model with mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mse = Sequential()\n",
    "model_mse.add(Dense(128, input_dim=200))\n",
    "model_mse.add(Activation('sigmoid'))\n",
    "model_mse.add(Dense(256))\n",
    "model_mse.add(Activation('sigmoid'))\n",
    "model_mse.add(Dense(5))\n",
    "model_mse.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD, Adam, RMSprop, Adagrad\n",
    "sgd = SGD(lr=0.01,momentum=0.0,decay=0.0,nesterov=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile model with specified loss and optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss with crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ce.compile(loss='categorical_crossentropy',\n",
    "\t\t\t\toptimizer=sgd,\n",
    "\t\t\t\tmetrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss with mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mse.compile(loss= 'mean_squared_error',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set the size of mini-batch and number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit models and use validation_split=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_ce = model_ce.fit(X_train, Y_train,\n",
    "\t\t\t\t\t\t\tbatch_size=batch_size,\n",
    "\t\t\t\t\t\t\tepochs=epochs,\n",
    "\t\t\t\t\t\t\tverbose=0,\n",
    "\t\t\t\t\t\t\tshuffle=True,\n",
    "                    \t\tvalidation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_mse = model_mse.fit(X_train, Y_train,\n",
    "\t\t\t\t\t\t\tbatch_size=batch_size,\n",
    "\t\t\t\t\t\t\tepochs=epochs,\n",
    "\t\t\t\t\t\t\tverbose=0,\n",
    "\t\t\t\t\t\t\tshuffle=True,\n",
    "                    \t\tvalidation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access the loss and accuracy in every epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_ce\t= history_ce.history.get('loss')\n",
    "acc_ce \t= history_ce.history.get('acc')\n",
    "loss_mse= history_mse.history.get('loss')\n",
    "acc_mse = history_mse.history.get('acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(0,figsize=(8,6))\n",
    "plt.subplot(121)\n",
    "plt.plot(range(len(loss_ce)), loss_ce,label='CE')\n",
    "plt.plot(range(len(loss_mse)), loss_mse,label='MSE')\n",
    "plt.title('Loss')\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.subplot(122)\n",
    "plt.plot(range(len(acc_ce)), acc_ce,label='CE')\n",
    "plt.plot(range(len(acc_mse)), acc_mse,label='MSE')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.savefig('01_lossFuncSelection.png',dpi=300,format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning rate (fit loss function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd1 = SGD(lr=0.1,momentum=0.0,decay=0.0,nesterov=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd2 = SGD(lr=0.01,momentum=0.0,decay=0.0,nesterov=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd3 = SGD(lr=0.001,momentum=0.0,decay=0.0,nesterov=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **sgd ＝ 0.1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ce.compile(loss='categorical_crossentropy',\n",
    "\t\t\t\toptimizer=sgd1,\n",
    "\t\t\t\tmetrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_ce1= model_ce.fit(X_train, Y_train,\n",
    "\t\t\t\t\t\t\tbatch_size=batch_size,\n",
    "\t\t\t\t\t\t\tepochs=epochs,\n",
    "\t\t\t\t\t\t\tverbose=0,\n",
    "\t\t\t\t\t\t\tshuffle=True,\n",
    "                    \t\tvalidation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_small = history_ce1.history.get('loss')\n",
    "acc_small = history_ce1.history.get('acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * **sgd ＝ 0.01**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ce.compile(loss='categorical_crossentropy',\n",
    "\t\t\t\toptimizer=sgd2,\n",
    "\t\t\t\tmetrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_ce2 = model_ce.fit(X_train, Y_train,\n",
    "\t\t\t\t\t\t\tbatch_size=batch_size,\n",
    "\t\t\t\t\t\t\tepochs=epochs,\n",
    "\t\t\t\t\t\t\tverbose=0,\n",
    "\t\t\t\t\t\t\tshuffle=True,\n",
    "                    \t\tvalidation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_median = history_ce2.history.get('loss')\n",
    "acc_median = history_ce2.history.get('acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * **sgd ＝ 0.001**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ce.compile(loss= 'categorical_crossentropy',\n",
    "              optimizer=sgd3,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_ce3 = model_ce.fit(X_train, Y_train,\n",
    "\t\t\t\t\t\t\tbatch_size=batch_size,\n",
    "\t\t\t\t\t\t\tepochs=epochs,\n",
    "\t\t\t\t\t\t\tverbose=0,\n",
    "\t\t\t\t\t\t\tshuffle=True,\n",
    "                    \t\tvalidation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_large = history_ce3.history.get('loss')\n",
    "acc_large = history_ce3.history.get('acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(0,figsize=(8,6))\n",
    "plt.subplot(121)\n",
    "plt.plot(range(len(loss_large)), loss_large,label='lr=0.1')\n",
    "plt.plot(range(len(loss_median)), loss_median,label='lr=0.01')\n",
    "plt.plot(range(len(loss_small)), loss_small,label='lr=0.001')\n",
    "plt.title('Loss')\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.subplot(122)\n",
    "plt.plot(range(len(acc_large)), acc_large,label='lr=0.1')\n",
    "plt.plot(range(len(acc_median)), acc_median,label='lr=0.01')\n",
    "plt.plot(range(len(acc_small)), acc_small,label='lr=0.001')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation function (fit loss function, learning rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sp = Sequential()\n",
    "model_sp.add(Dense(128, input_dim=200))\n",
    "model_sp.add(Activation('relu'))\n",
    "model_sp.add(Dense(256))\n",
    "model_sp.add(Activation('relu'))\n",
    "model_sp.add(Dense(5))\n",
    "model_sp.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sp.compile(loss= 'categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_sp = model_sp.fit(X_train, Y_train,\n",
    "\t\t\t\t\t\t\tbatch_size=batch_size,\n",
    "\t\t\t\t\t\t\tepochs=epochs,\n",
    "\t\t\t\t\t\t\tverbose=0,\n",
    "\t\t\t\t\t\t\tshuffle=True,\n",
    "                    \t\tvalidation_split=0.1)\n",
    "\n",
    "loss_sp = history_sp.history.get('loss')\n",
    "acc_sp = history_sp.history.get('acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bm = Sequential()\n",
    "model_bm.add(Dense(128, input_dim=200))\n",
    "model_bm.add(Activation('sigmoid'))\n",
    "model_bm.add(Dense(256))\n",
    "model_bm.add(Activation('sigmoid'))\n",
    "model_bm.add(Dense(5))\n",
    "model_bm.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bm.compile(loss='categorical_crossentropy',\n",
    "\t\t\t\toptimizer=sgd,\n",
    "\t\t\t\tmetrics=['accuracy'])\n",
    "history_bm = model_bm.fit(X_train, Y_train,\n",
    "\t\t\t\t\t\t\tbatch_size=batch_size,\n",
    "\t\t\t\t\t\t\tepochs=epochs,\n",
    "\t\t\t\t\t\t\tverbose=0,\n",
    "\t\t\t\t\t\t\tshuffle=True,\n",
    "                    \t\tvalidation_split=0.1)\n",
    "loss_bm\t= history_bm.history.get('loss')\n",
    "acc_bm \t= history_bm.history.get('acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(0,figsize=(8,6))\n",
    "plt.subplot(121)\n",
    "plt.plot(range(len(loss_sp)),loss_sp,label='relu')\n",
    "plt.plot(range(len(loss_bm)),loss_bm,label='Sigmoid')\n",
    "plt.title('Loss')\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.subplot(122)\n",
    "plt.plot(range(len(acc_sp)),acc_sp,label='relu')\n",
    "plt.plot(range(len(acc_bm)),acc_bm,label='Sigmoid')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer\n",
    "Optimization algorithms helps us to **minimize** a **Loss** function. <br>\n",
    "Here, we will present four different optimizers.<br>\n",
    "### How to Select Optimizers\n",
    "* People usually use **Adam**\n",
    "    * Adaptive learning rate for every weights \n",
    "    * Momentum included\n",
    "* Recommend **RMSprop** in RNN\n",
    "    * **explosive gradient** may happen when training \n",
    "    * Solution : Clip gradient \n",
    "    \n",
    "### Parameters common to all Keras optimizers\n",
    "* clipnorm\n",
    "    * EX. sgd = optimizers.SGD(lr=0.01, **clipnorm=1.**)\n",
    "    * All parameter gradients will be clipped to a maximum norm of 1.\n",
    "* clipvalue\n",
    "    * EX. sgd = optimizers.SGD(lr=0.01, **clipvalue=0.5**)\n",
    "    * All parameter gradients will be clipped to a maximum value of 0.5 and a minimum value of -0.5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD, RMSprop, Adagrad, Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD\n",
    "Stochastic Gradient Descent\n",
    "* **lr** : float >= 0. Learning rate.\n",
    "* **momentum** : float >= 0. Accelerates SGD in the relevant direction.\n",
    "* **decay**: float >= 0. Learning rate decay over each update.\n",
    "* **nesterov**: boolean. Whether to apply Nesterov momentum.\n",
    "\n",
    "---\n",
    "![](https://i.imgur.com/vpCTJih.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sp.compile(loss= 'categorical_crossentropy',\n",
    "              \t\toptimizer=SGD(lr=0.01), \n",
    "              \t\tmetrics=['accuracy'])\n",
    "history_sgd = model_sp.fit(X_train, Y_train,\n",
    "\t\t\t\t\t\t\tbatch_size=batch_size,\n",
    "\t\t\t\t\t\t\tepochs=epochs,\n",
    "\t\t\t\t\t\t\tverbose=0,\n",
    "\t\t\t\t\t\t\tshuffle=True,\n",
    "                    \t\tvalidation_split=0.1)\n",
    "\n",
    "loss_sgd = history_sgd.history.get('loss')\n",
    "acc_sgd = history_sgd.history.get('acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adagrad\n",
    "Adaptive Learning Rate <br>\n",
    "Modified by the **root mean square** of all **previous gradients**.\n",
    "\n",
    "---\n",
    "![](https://i.imgur.com/Vp0HPn0.png)\n",
    "![](https://i.imgur.com/BoYUtM7.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sp.compile(loss= 'categorical_crossentropy',\n",
    "              \t\toptimizer=Adagrad(lr=0.01),\n",
    "              \t\tmetrics=['accuracy'])\n",
    "history_ada = model_sp.fit(X_train, Y_train,\n",
    "\t\t\t\t\t\t\tbatch_size=batch_size,\n",
    "\t\t\t\t\t\t\tepochs=epochs,\n",
    "\t\t\t\t\t\t\tverbose=0,\n",
    "\t\t\t\t\t\t\tshuffle=True,\n",
    "                    \t\tvalidation_split=0.1)\n",
    "\n",
    "loss_ada = history_ada.history.get('loss')\n",
    "acc_ada = history_ada.history.get('acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSprop\n",
    "Similar with Adagrad, also modified by previous gradients. <br>\n",
    "RMSprop is a good choice for **RNN**.\n",
    "\n",
    "---\n",
    "![](https://i.imgur.com/0Lf7JUd.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sp.compile(loss= 'categorical_crossentropy',\n",
    "              \t\toptimizer=RMSprop(lr=0.01),\n",
    "              \t\tmetrics=['accuracy'])\n",
    "history_rms = model_sp.fit(X_train, Y_train,\n",
    "\t\t\t\t\t\t\tbatch_size=batch_size,\n",
    "\t\t\t\t\t\t\tepochs=epochs,\n",
    "\t\t\t\t\t\t\tverbose=0,\n",
    "\t\t\t\t\t\t\tshuffle=True,\n",
    "                    \t\tvalidation_split=0.1)\n",
    "\n",
    "loss_rms = history_rms.history.get('loss')\n",
    "acc_rms = history_rms.history.get('acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam\n",
    "Similar with RMSprop + Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sp.compile(loss= 'categorical_crossentropy',\n",
    "              \t\toptimizer=Adam(lr=0.01),\n",
    "              \t\tmetrics=['accuracy'])\n",
    "history_adam = model_sp.fit(X_train, Y_train,\n",
    "\t\t\t\t\t\t\tbatch_size=batch_size,\n",
    "\t\t\t\t\t\t\tepochs=epochs,\n",
    "\t\t\t\t\t\t\tverbose=0,\n",
    "\t\t\t\t\t\t\tshuffle=True,\n",
    "                    \t\tvalidation_split=0.1)\n",
    "\n",
    "loss_adam= history_adam.history.get('loss')\n",
    "acc_adam = history_adam.history.get('acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "---\n",
    "**Adagrad, Adadelta** and **RMSprop** find the correct direction in a short time. <br>\n",
    "![](https://static.leiphone.com/uploads/new/article/740_740/201706/5943a067842cf.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(0,figsize=(8,6))\n",
    "plt.subplot(121)\n",
    "plt.plot(range(len(loss_adam)), loss_adam,label='Adam')\n",
    "plt.plot(range(len(loss_sgd)), loss_sgd,label='SGD')\n",
    "plt.plot(range(len(loss_rms)), loss_rms,label='RMS')\n",
    "plt.plot(range(len(loss_ada)), loss_ada,label='Ada')\n",
    "\n",
    "plt.title('Loss')\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.subplot(122)\n",
    "plt.plot(range(len(acc_adam)), acc_adam,label='Adam')\n",
    "plt.plot(range(len(acc_sgd)), acc_sgd,label='SGD')\n",
    "plt.plot(range(len(acc_rms)), acc_rms,label='RMS')\n",
    "plt.plot(range(len(acc_ada)), acc_ada,label='Ada')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
